{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7805e5bd",
   "metadata": {},
   "source": [
    "# Title : Sentiment Analysis on Data Science Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd5732",
   "metadata": {},
   "source": [
    "<img src=\"sentiment.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547165fa",
   "metadata": {},
   "source": [
    "Sentiment analysis, also referred to as opinion mining, is an approach to natural language processing (NLP) that identifies the emotional tone behind a body of text. This is a popular way for organizations to determine and categorize opinions about a product, service, or idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a0baf",
   "metadata": {},
   "source": [
    "The data source for these articles is the **insights.blackcoffer.com** site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a38c9cb",
   "metadata": {},
   "source": [
    "#### Time Line for the Project:\n",
    "- Import Libraries and Data Set\n",
    "- Perfrom text Scraping\n",
    "- Data Preprocessing\n",
    "- Perform Sentiment Analysis\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470c583",
   "metadata": {},
   "source": [
    "## Importing libraries and data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319ae8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data analysis\n",
    "import numpy as np # computation\n",
    "from selenium import webdriver # read data from url (automation)\n",
    "from selenium.webdriver.common.by import By # scrape data by field (segmementing)\n",
    "from selenium.webdriver.support import expected_conditions as EC #conditions used for WebDriverWait\n",
    "from selenium.webdriver.support.ui import WebDriverWait #waits for condition to be fufilled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a82ac0",
   "metadata": {},
   "source": [
    "#### Read link file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de328545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0       1  https://insights.blackcoffer.com/how-is-login-...\n",
       "1       2  https://insights.blackcoffer.com/how-does-ai-h...\n",
       "2       3  https://insights.blackcoffer.com/ai-and-its-im...\n",
       "3       4  https://insights.blackcoffer.com/how-do-deep-l...\n",
       "4       5  https://insights.blackcoffer.com/how-artificia..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = pd.read_excel('Input.xlsx')\n",
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2a638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Safari() # for installing drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d191d0f",
   "metadata": {},
   "source": [
    "#### Making functions to scrape data from the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd92d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## funtion to scrape data from the links\n",
    "def scrape_data(link):\n",
    "    global driver\n",
    "    driver.get(link)\n",
    "    \n",
    "    content = WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.td-post-content')))\n",
    "    \n",
    "    return content.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59fbb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to save the scrapped files\n",
    "def save_file(scrapdata):\n",
    "    for data in scrapdata:\n",
    "        name=str(data['URL_ID'])+\".txt\"\n",
    "        \n",
    "        f=open(\"./Articles/\"+name,'w+',encoding='utf-8')\n",
    "        f.write(data['TEXT'])\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5d358",
   "metadata": {},
   "source": [
    "## Perform scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for index, row in links.iterrows():\n",
    "    item={}\n",
    "    item['URL_ID']=row['URL_ID']\n",
    "    try:\n",
    "        item['TEXT']=scrape_data(row['URL'])\n",
    "    except:\n",
    "        item['TEXT']='Data not found' # Output text (in case of data not found)\n",
    "    #item['TEXT']=scrape_data(row['URL'])\n",
    "    data.append(item)\n",
    "save_file(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a81928d",
   "metadata": {},
   "source": [
    "#### Making a data frame of scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa2eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "path = 'Articles'\n",
    "files = listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91764d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"filenumber\",\"text\"])\n",
    "\n",
    "for file in files:\n",
    "    f= open(\"./Articles/\"+file,\"r\",encoding='utf-8')\n",
    "    content = f.read()\n",
    "    sr = file.replace(\".0.txt\",\"\")\n",
    "    number = int(sr.split(\".\")[0])\n",
    "    \n",
    "    new_row = pd.DataFrame({\"filenumber\":number,\"text\":content}, index=[0])\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc312c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55aa4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"filenumber\")\n",
    "df.to_csv(\"content.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d5bec",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce387dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('content.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e9e75",
   "metadata": {},
   "source": [
    "#### Remove corrupted cells - cells containing css or Data not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b098645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_remove1 = 'custom css'\n",
    "string_to_remove2 = 'Data not found'\n",
    "\n",
    "# Dropping the rows that contain string_to_remove1 and string_to_remove2\n",
    "df = df[~df['text'].str.contains(string_to_remove1)]\n",
    "df = df[~df['text'].str.contains(string_to_remove2)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643afc95",
   "metadata": {},
   "source": [
    "##### Now the text is clean, start data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa316ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['URL']=links['URL']\n",
    "df[\"Number of sentences\"]= df['text'].apply(lambda x: len(x.split('.')))\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_forms():    \n",
    "    return {\n",
    "        \"cant\":\"can not\",\n",
    "        \"dont\":\"do not\",\n",
    "        \"wont\":\"will not\",\n",
    "        \"ain't\":\"is not\",\n",
    "        \"amn't\":\"am not\",\n",
    "        \"aren't\":\"are not\",\n",
    "        \"can't\":\"cannot\",\n",
    "        \"'cause\":\"because\",\n",
    "        \"couldn't\":\"could not\",\n",
    "        \"couldn't've\":\"could not have\",\n",
    "        \"could've\":\"could have\",\n",
    "        \"daren't\":\"dare not\",\n",
    "        \"daresn't\":\"dare not\",\n",
    "        \"dasn't\":\"dare not\",\n",
    "        \"didn't\":\"did not\",\n",
    "        \"doesn't\":\"does not\",\n",
    "        \"don't\":\"do not\",\n",
    "        \"e'er\":\"ever\",\n",
    "        \"em\":\"them\",\n",
    "        \"everyone's\":\"everyone is\",\n",
    "        \"finna\":\"fixing to\",\n",
    "        \"gimme\":\"give me\",\n",
    "        \"gonna\":\"going to\",\n",
    "        \"gon't\":\"go not\",\n",
    "        \"gotta\":\"got to\",\n",
    "        \"hadn't\":\"had not\",\n",
    "        \"hasn't\":\"has not\",\n",
    "        \"haven't\":\"have not\",\n",
    "        \"he'd\":\"he would\",\n",
    "        \"he'll\":\"he will\",\n",
    "        \"he's\":\"he is\",\n",
    "        \"he've\":\"he have\",\n",
    "        \"how'd\":\"how would\",\n",
    "        \"how'll\":\"how will\",\n",
    "        \"how're\":\"how are\",\n",
    "        \"how's\":\"how is\",\n",
    "        \"I'd\":\"I would\",\n",
    "        \"I'll\":\"I will\",\n",
    "        \"I'm\":\"I am\",\n",
    "        \"I'm'a\":\"I am about to\",\n",
    "        \"I'm'o\":\"I am going to\",\n",
    "        \"isn't\":\"is not\",\n",
    "        \"it'd\":\"it would\",\n",
    "        \"it'll\":\"it will\",\n",
    "        \"it's\":\"it is\",\n",
    "        \"I've\":\"I have\",\n",
    "        \"kinda\":\"kind of\",\n",
    "        \"let's\":\"let us\",\n",
    "        \"mayn't\":\"may not\",\n",
    "        \"may've\":\"may have\",\n",
    "        \"mightn't\":\"might not\",\n",
    "        \"might've\":\"might have\",\n",
    "        \"mustn't\":\"must not\",\n",
    "        \"mustn't've\":\"must not have\",\n",
    "        \"must've\":\"must have\",\n",
    "        \"needn't\":\"need not\",\n",
    "        \"ne'er\":\"never\",\n",
    "        \"o'\":\"of\",\n",
    "        \"o'er\":\"over\",\n",
    "        \"ol'\":\"old\",\n",
    "        \"oughtn't\":\"ought not\",\n",
    "        \"shalln't\":\"shall not\",\n",
    "        \"shan't\":\"shall not\",\n",
    "        \"she'd\":\"she would\",\n",
    "        \"she'll\":\"she will\",\n",
    "        \"she's\":\"she is\",\n",
    "        \"shouldn't\":\"should not\",\n",
    "        \"shouldn't've\":\"should not have\",\n",
    "        \"should've\":\"should have\",\n",
    "        \"somebody's\":\"somebody is\",\n",
    "        \"someone's\":\"someone is\",\n",
    "        \"something's\":\"something is\",\n",
    "        \"that'd\":\"that would\",\n",
    "        \"that'll\":\"that will\",\n",
    "        \"that're\":\"that are\",\n",
    "        \"that's\":\"that is\",\n",
    "        \"there'd\":\"there would\",\n",
    "        \"there'll\":\"there will\",\n",
    "        \"there're\":\"there are\",\n",
    "        \"there's\":\"there is\",\n",
    "        \"these're\":\"these are\",\n",
    "        \"they'd\":\"they would\",\n",
    "        \"they'll\":\"they will\",\n",
    "        \"they're\":\"they are\",\n",
    "        \"they've\":\"they have\",\n",
    "        \"this's\":\"this is\",\n",
    "        \"those're\":\"those are\",\n",
    "        \"'tis\":\"it is\",\n",
    "        \"'twas\":\"it was\",\n",
    "        \"wanna\":\"want to\",\n",
    "        \"wasn't\":\"was not\",\n",
    "        \"we'd\":\"we would\",\n",
    "        \"we'd've\":\"we would have\",\n",
    "        \"we'll\":\"we will\",\n",
    "        \"we're\":\"we are\",\n",
    "        \"weren't\":\"were not\",\n",
    "        \"we've\":\"we have\",\n",
    "        \"what'd\":\"what did\",\n",
    "        \"what'll\":\"what will\",\n",
    "        \"what're\":\"what are\",\n",
    "        \"what's\":\"what is\",\n",
    "        \"what've\":\"what have\",\n",
    "        \"when's\":\"when is\",\n",
    "        \"where'd\":\"where did\",\n",
    "        \"where're\":\"where are\",\n",
    "        \"where's\":\"where is\",\n",
    "        \"where've\":\"where have\",\n",
    "        \"which's\":\"which is\",\n",
    "        \"who'd\":\"who would\",\n",
    "        \"who'd've\":\"who would have\",\n",
    "        \"who'll\":\"who will\",\n",
    "        \"who're\":\"who are\",\n",
    "        \"who's\":\"who is\",\n",
    "        \"who've\":\"who have\",\n",
    "        \"why'd\":\"why did\",\n",
    "        \"why're\":\"why are\",\n",
    "        \"why's\":\"why is\",\n",
    "        \"won't\":\"will not\",\n",
    "        \"wouldn't\":\"would not\",\n",
    "        \"would've\":\"would have\",\n",
    "        \"y'all\":\"you all\",\n",
    "        \"you'd\":\"you would\",\n",
    "        \"you'll\":\"you will\",\n",
    "        \"you're\":\"you are\",\n",
    "        \"you've\":\"you have\",\n",
    "        \"Whatcha\":\"What are you\",\n",
    "        \"luv\":\"love\",\n",
    "        \"sux\":\"sucks\",\n",
    "        \"couldn't\":\"could not\",\n",
    "        \"wouldn't\":\"would not\",\n",
    "        \"shouldn't\":\"should not\",\n",
    "        \"im\":\"i am\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558406c8",
   "metadata": {},
   "source": [
    "Now we'll clean the text to get rid of punctuation and links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f38bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  ##check if a particular string matches a given regular expression\n",
    "import string\n",
    "\n",
    "## funtion to replace the short forms \n",
    "def normalization(data):\n",
    "    data = str(data).lower()\n",
    "    # Take out all URLs\n",
    "    data = re.sub('((www.[^\\s]+)|(https?://[^\\s]+))',' ',data)\n",
    "    data = re.sub(r'#([^\\s]+)', r'\\1', data)\n",
    "\n",
    "    # Number\n",
    "    data = ''.join([i for i in data if not i.isdigit()])\n",
    "\n",
    "    # Punctuation\n",
    "    for sym in string.punctuation:\n",
    "        data = data.replace(sym, \" \")\n",
    "    short_form = short_forms()\n",
    "    data = data.replace(\"’\",\"'\")\n",
    "    words = data.split()\n",
    "    converted = [short_form[word] if word in short_form else word for word in words]\n",
    "    data = \" \".join(converted)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0004a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['text'].apply(normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf5de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a56aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24801d4",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf22a33",
   "metadata": {},
   "source": [
    "First we import a dictionary which contains the sentiment analysis words which will act as a reference for our data set words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = pd.read_csv('LoughranMcDonald_MasterDictionary_2020.csv')\n",
    "guide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf4ffe",
   "metadata": {},
   "source": [
    "Assigning Positive and Negative score to our words based on the dictionary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [] \n",
    "neg =[]\n",
    "Uncertain = []\n",
    "for index,row in guide.iterrows():\n",
    "    if row['Negative']>0:\n",
    "        neg.append(row['Word'].lower())\n",
    "    elif row['Positive']>0:\n",
    "        pos.append(row['Word'].lower())\n",
    "    elif row['Uncertainty']>0:\n",
    "        Uncertain.append(row['Word'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29aab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positivescore(text):\n",
    "    score = 0\n",
    "    global pos\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in pos:\n",
    "            score +=1\n",
    "    return score\n",
    "    \n",
    "def negativescore(text):\n",
    "    score = 0\n",
    "    global neg\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in neg:\n",
    "            score +=1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Positive Score']=df['text'].apply(positivescore)\n",
    "df['Negative Score']=df['text'].apply(negativescore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26faa810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76521fb2",
   "metadata": {},
   "source": [
    "Getting all other parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54c4f9",
   "metadata": {},
   "source": [
    "- **Subjectivity score** is just to identify if a text is written from a more factual basis or opinionated basis,\n",
    "where 0 means it is factual whilst 1 means it is highly subjective (opinionated).\n",
    "- **Polarity** represents the sentiment intensity, it measures the degree of positivty, neutrality and negativity. The polarity score can range from -1 to 1, with -1 indicating strong negative sentiment, 0 indicating neutral sentiment, and 1 indicating strong positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3225ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WORD COUNT']=df['text'].apply(lambda x:len(x.split()))\n",
    "df['POLARITY SCORE']=(df['Positive Score']-df['Negative Score'])/ ((df['Positive Score'] + df['Negative Score']) + 0.000001)\n",
    "df['SUBJECTIVITY SCORE']=(df['Positive Score'] + df['Negative Score'])/ ((df['WORD COUNT']) + 0.000001)\n",
    "df['AVG SENTENCE LENGTH']=df['WORD COUNT']/df['Number of sentences']\n",
    "df['AVG NUMBER OF WORDS PER SENTENCE'] = df['WORD COUNT']/df['Number of sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9384e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c64cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for avg length of words\n",
    "def avgwordlength(text):\n",
    "    words = text.split()\n",
    "    no_of_words=len(words)\n",
    "    total_char=0\n",
    "    for word in words:\n",
    "        total_char+=len(word)\n",
    "    return total_char/no_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a13cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for seeing if the sentence has pronoun\n",
    "def pronoun(text):\n",
    "    pronouns = r\"(\\b(s?i|me|we|my|ours|us|I|Me|We|My|Ours|Us)\\b)\"\n",
    "    result = 0\n",
    "\n",
    "    matches = re.finditer(pronouns,text,re.MULTILINE)\n",
    "    for nummatch,match in enumerate(matches):\n",
    "        result+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e959ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AVG WORD LENGTH']=df['text'].apply(avgwordlength)\n",
    "df['PERSONAL PRONOUNS']=df['text'].apply(pronoun)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c22f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f35908",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf97ee8",
   "metadata": {},
   "source": [
    "On looking at the data we find that every article has a factual tone, so we'll not include subjectivity score in final judgement.\n",
    "Using polarity score, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f51b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['POLARITY SCORE'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13621250",
   "metadata": {},
   "source": [
    "Now we see the median polarity score of all articles, we infer that with a score of **-0.17647058304498286** these data science articles have a **pretty neutral** sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3742b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
